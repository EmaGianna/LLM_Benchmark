{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **ANALISIS DATOS LLMs**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6jzXTfFV-NpO",
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "from lib_llm_benchmark import staticals_functions\n",
        "from lib_llm_benchmark import utils\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **MAIN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tbl_name: gemma_7b_data1, index 0\n",
            "tbl_name: llama2_data1, index 1\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # conexion a la BBDD\n",
        "    path = \"/mnt/e/trabajo/sysberisso/GIT_REPOS/LLM_Benchmark/prompts/db\"\n",
        "    \n",
        "    con = sqlite3.connect(f'{path}/prompt_sqlite.db')\n",
        "    # consulto los objetos de la BBDD para obtener los nombres de los modelos gemma_7b y llama2\n",
        "    df_view = pd.read_sql_query(\"SELECT name FROM sqlite_master where type='view' and name not like 'extra_%' limit 2\" , con)\n",
        "\n",
        "    llm_df = pd.DataFrame()\n",
        "    \n",
        "    for index, row in df_view.iterrows():\n",
        "      print(f\"tbl_name: {row['name']}, index {index}\")\n",
        "      name_tbl = df_view.iloc[index]['name']\n",
        "      sql_query = f\"SELECT id_promtp, answers FROM {name_tbl}\" #f\"SELECT id_promtp, answers FROM {row['name']}\"\n",
        "      df_prompts = pd.read_sql_query(sql_query, con)\n",
        "  \n",
        "      #empty_df = empty_df.append(calculo_valores_estadisticas_linguisticas(df_prompts, name_tbl))\n",
        "      llm_df = pd.concat([llm_df, staticals_functions.get_df_linguistics_statistics_values(df_prompts, name_tbl)])\n",
        "           \n",
        "    llm_df = llm_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_promtp</th>\n",
              "      <th>answers</th>\n",
              "      <th>llm_model</th>\n",
              "      <th>lang</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>sentence_count</th>\n",
              "      <th>char_count</th>\n",
              "      <th>letter_count</th>\n",
              "      <th>lexicon_count</th>\n",
              "      <th>avg_sentence_length</th>\n",
              "      <th>avg_letter_per_word</th>\n",
              "      <th>qtty_stopwords</th>\n",
              "      <th>qtty_words</th>\n",
              "      <th>lexical_density</th>\n",
              "      <th>lexical_richness</th>\n",
              "      <th>analyze_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Claro, estoy aquí para ayudarte. ¿En qué puedo...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>0.75</td>\n",
              "      <td>2</td>\n",
              "      <td>51</td>\n",
              "      <td>47</td>\n",
              "      <td>10</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.70</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>La capital de Francia es **París**.</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.17</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>¡Claro que sí! Argentina es un país increíble ...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>22.59</td>\n",
              "      <td>19</td>\n",
              "      <td>1538</td>\n",
              "      <td>1390</td>\n",
              "      <td>282</td>\n",
              "      <td>14.8</td>\n",
              "      <td>4.93</td>\n",
              "      <td>120</td>\n",
              "      <td>297</td>\n",
              "      <td>49.831650</td>\n",
              "      <td>0.498316</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>## Inteligencia Artificial: La próxima generac...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>21.37</td>\n",
              "      <td>17</td>\n",
              "      <td>1455</td>\n",
              "      <td>1355</td>\n",
              "      <td>236</td>\n",
              "      <td>13.9</td>\n",
              "      <td>5.74</td>\n",
              "      <td>91</td>\n",
              "      <td>250</td>\n",
              "      <td>54.800000</td>\n",
              "      <td>0.548000</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>\"Martian Chronicles\" by Ray Bradbury is a coll...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>en</td>\n",
              "      <td>7.51</td>\n",
              "      <td>4</td>\n",
              "      <td>511</td>\n",
              "      <td>499</td>\n",
              "      <td>89</td>\n",
              "      <td>22.3</td>\n",
              "      <td>5.61</td>\n",
              "      <td>2</td>\n",
              "      <td>89</td>\n",
              "      <td>76.404494</td>\n",
              "      <td>0.764045</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>La sombra del poder se aleja,\\nel corazón del ...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>11.30</td>\n",
              "      <td>12</td>\n",
              "      <td>769</td>\n",
              "      <td>741</td>\n",
              "      <td>164</td>\n",
              "      <td>13.7</td>\n",
              "      <td>4.52</td>\n",
              "      <td>84</td>\n",
              "      <td>164</td>\n",
              "      <td>57.926829</td>\n",
              "      <td>0.579268</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>**Título:** El peor día de la vida de Juan\\n\\n...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>20.76</td>\n",
              "      <td>32</td>\n",
              "      <td>1413</td>\n",
              "      <td>1293</td>\n",
              "      <td>312</td>\n",
              "      <td>9.8</td>\n",
              "      <td>4.14</td>\n",
              "      <td>138</td>\n",
              "      <td>324</td>\n",
              "      <td>46.666667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>```python\\nprint(\"Hola, mundo!\")\\n```\\n\\nEste ...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>2.41</td>\n",
              "      <td>5</td>\n",
              "      <td>164</td>\n",
              "      <td>138</td>\n",
              "      <td>30</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>13</td>\n",
              "      <td>31</td>\n",
              "      <td>87.096774</td>\n",
              "      <td>0.870968</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>No se ha proporcionado ningún conjunto de dato...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>2.78</td>\n",
              "      <td>3</td>\n",
              "      <td>189</td>\n",
              "      <td>184</td>\n",
              "      <td>38</td>\n",
              "      <td>12.7</td>\n",
              "      <td>4.84</td>\n",
              "      <td>17</td>\n",
              "      <td>38</td>\n",
              "      <td>76.315789</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>```python\\nfrom pyspark.sql.functions import m...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>11.78</td>\n",
              "      <td>11</td>\n",
              "      <td>802</td>\n",
              "      <td>702</td>\n",
              "      <td>135</td>\n",
              "      <td>12.3</td>\n",
              "      <td>5.20</td>\n",
              "      <td>44</td>\n",
              "      <td>153</td>\n",
              "      <td>44.078947</td>\n",
              "      <td>0.440789</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>\\n¡Buenos días! ¡Claro que sí! Estoy aquí para...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>2.60</td>\n",
              "      <td>3</td>\n",
              "      <td>177</td>\n",
              "      <td>169</td>\n",
              "      <td>39</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.33</td>\n",
              "      <td>21</td>\n",
              "      <td>39</td>\n",
              "      <td>82.051282</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "      <td>\\nLa capital de Francia es París.</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>25</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.17</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3</td>\n",
              "      <td>\\n¡Por supuesto! Argentina es un país fascinan...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>29.10</td>\n",
              "      <td>25</td>\n",
              "      <td>1981</td>\n",
              "      <td>1918</td>\n",
              "      <td>406</td>\n",
              "      <td>16.2</td>\n",
              "      <td>4.72</td>\n",
              "      <td>168</td>\n",
              "      <td>406</td>\n",
              "      <td>41.379310</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4</td>\n",
              "      <td>\\nInteligencia Artificial (IA) es el campo de ...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>18.36</td>\n",
              "      <td>10</td>\n",
              "      <td>1250</td>\n",
              "      <td>1224</td>\n",
              "      <td>227</td>\n",
              "      <td>22.7</td>\n",
              "      <td>5.39</td>\n",
              "      <td>99</td>\n",
              "      <td>230</td>\n",
              "      <td>54.782609</td>\n",
              "      <td>0.547826</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "      <td>\\nSure! Here is the translation of the text in...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>en</td>\n",
              "      <td>8.04</td>\n",
              "      <td>4</td>\n",
              "      <td>547</td>\n",
              "      <td>532</td>\n",
              "      <td>96</td>\n",
              "      <td>24.0</td>\n",
              "      <td>5.54</td>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "      <td>76.041667</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6</td>\n",
              "      <td>\\nEl aire es libre, la brisa del mar\\nUna sens...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>11.43</td>\n",
              "      <td>1</td>\n",
              "      <td>778</td>\n",
              "      <td>764</td>\n",
              "      <td>180</td>\n",
              "      <td>180.0</td>\n",
              "      <td>4.24</td>\n",
              "      <td>99</td>\n",
              "      <td>180</td>\n",
              "      <td>52.222222</td>\n",
              "      <td>0.522222</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7</td>\n",
              "      <td>Título: \"The Audition\"\\n\\nAct 1:\\n\\nThe scene ...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>en</td>\n",
              "      <td>24.91</td>\n",
              "      <td>22</td>\n",
              "      <td>1696</td>\n",
              "      <td>1628</td>\n",
              "      <td>361</td>\n",
              "      <td>16.4</td>\n",
              "      <td>4.51</td>\n",
              "      <td>21</td>\n",
              "      <td>361</td>\n",
              "      <td>52.908587</td>\n",
              "      <td>0.529086</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8</td>\n",
              "      <td>```\\nprint(\"Hola, mundo!\")\\n```\\nEste código u...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>10.30</td>\n",
              "      <td>8</td>\n",
              "      <td>701</td>\n",
              "      <td>645</td>\n",
              "      <td>125</td>\n",
              "      <td>15.6</td>\n",
              "      <td>5.16</td>\n",
              "      <td>53</td>\n",
              "      <td>129</td>\n",
              "      <td>50.387597</td>\n",
              "      <td>0.503876</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>9</td>\n",
              "      <td>\\n ¡Claro! Para analizar este conjunto de dato...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>20.18</td>\n",
              "      <td>13</td>\n",
              "      <td>1374</td>\n",
              "      <td>1232</td>\n",
              "      <td>246</td>\n",
              "      <td>18.9</td>\n",
              "      <td>5.01</td>\n",
              "      <td>102</td>\n",
              "      <td>257</td>\n",
              "      <td>43.190661</td>\n",
              "      <td>0.431907</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>10</td>\n",
              "      <td>\\nPuedes crear una función en PySpark utilizan...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>18.32</td>\n",
              "      <td>14</td>\n",
              "      <td>1247</td>\n",
              "      <td>1117</td>\n",
              "      <td>202</td>\n",
              "      <td>14.4</td>\n",
              "      <td>5.53</td>\n",
              "      <td>82</td>\n",
              "      <td>211</td>\n",
              "      <td>44.549763</td>\n",
              "      <td>0.445498</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id_promtp                                            answers llm_model  \\\n",
              "0           1  Claro, estoy aquí para ayudarte. ¿En qué puedo...     gemma   \n",
              "1           2                La capital de Francia es **París**.     gemma   \n",
              "2           3  ¡Claro que sí! Argentina es un país increíble ...     gemma   \n",
              "3           4  ## Inteligencia Artificial: La próxima generac...     gemma   \n",
              "4           5  \"Martian Chronicles\" by Ray Bradbury is a coll...     gemma   \n",
              "5           6  La sombra del poder se aleja,\\nel corazón del ...     gemma   \n",
              "6           7  **Título:** El peor día de la vida de Juan\\n\\n...     gemma   \n",
              "7           8  ```python\\nprint(\"Hola, mundo!\")\\n```\\n\\nEste ...     gemma   \n",
              "8           9  No se ha proporcionado ningún conjunto de dato...     gemma   \n",
              "9          10  ```python\\nfrom pyspark.sql.functions import m...     gemma   \n",
              "10          1  \\n¡Buenos días! ¡Claro que sí! Estoy aquí para...    llama2   \n",
              "11          2                  \\nLa capital de Francia es París.    llama2   \n",
              "12          3  \\n¡Por supuesto! Argentina es un país fascinan...    llama2   \n",
              "13          4  \\nInteligencia Artificial (IA) es el campo de ...    llama2   \n",
              "14          5  \\nSure! Here is the translation of the text in...    llama2   \n",
              "15          6  \\nEl aire es libre, la brisa del mar\\nUna sens...    llama2   \n",
              "16          7  Título: \"The Audition\"\\n\\nAct 1:\\n\\nThe scene ...    llama2   \n",
              "17          8  ```\\nprint(\"Hola, mundo!\")\\n```\\nEste código u...    llama2   \n",
              "18          9  \\n ¡Claro! Para analizar este conjunto de dato...    llama2   \n",
              "19         10  \\nPuedes crear una función en PySpark utilizan...    llama2   \n",
              "\n",
              "   lang  reading_time  sentence_count  char_count  letter_count  \\\n",
              "0    es          0.75               2          51            47   \n",
              "1    es          0.44               1          30            25   \n",
              "2    es         22.59              19        1538          1390   \n",
              "3    es         21.37              17        1455          1355   \n",
              "4    en          7.51               4         511           499   \n",
              "5    es         11.30              12         769           741   \n",
              "6    es         20.76              32        1413          1293   \n",
              "7    es          2.41               5         164           138   \n",
              "8    es          2.78               3         189           184   \n",
              "9    es         11.78              11         802           702   \n",
              "10   es          2.60               3         177           169   \n",
              "11   es          0.38               1          26            25   \n",
              "12   es         29.10              25        1981          1918   \n",
              "13   es         18.36              10        1250          1224   \n",
              "14   en          8.04               4         547           532   \n",
              "15   es         11.43               1         778           764   \n",
              "16   en         24.91              22        1696          1628   \n",
              "17   es         10.30               8         701           645   \n",
              "18   es         20.18              13        1374          1232   \n",
              "19   es         18.32              14        1247          1117   \n",
              "\n",
              "    lexicon_count  avg_sentence_length  avg_letter_per_word  qtty_stopwords  \\\n",
              "0              10                  5.0                 4.70               3   \n",
              "1               6                  6.0                 4.17               3   \n",
              "2             282                 14.8                 4.93             120   \n",
              "3             236                 13.9                 5.74              91   \n",
              "4              89                 22.3                 5.61               2   \n",
              "5             164                 13.7                 4.52              84   \n",
              "6             312                  9.8                 4.14             138   \n",
              "7              30                  6.0                 4.60              13   \n",
              "8              38                 12.7                 4.84              17   \n",
              "9             135                 12.3                 5.20              44   \n",
              "10             39                 13.0                 4.33              21   \n",
              "11              6                  6.0                 4.17               3   \n",
              "12            406                 16.2                 4.72             168   \n",
              "13            227                 22.7                 5.39              99   \n",
              "14             96                 24.0                 5.54               1   \n",
              "15            180                180.0                 4.24              99   \n",
              "16            361                 16.4                 4.51              21   \n",
              "17            125                 15.6                 5.16              53   \n",
              "18            246                 18.9                 5.01             102   \n",
              "19            202                 14.4                 5.53              82   \n",
              "\n",
              "    qtty_words  lexical_density  lexical_richness analyze_sentiment  \n",
              "0           10        90.000000          0.900000           Neutral  \n",
              "1            6       100.000000          1.000000           Neutral  \n",
              "2          297        49.831650          0.498316           Neutral  \n",
              "3          250        54.800000          0.548000          Negative  \n",
              "4           89        76.404494          0.764045          Positive  \n",
              "5          164        57.926829          0.579268          Negative  \n",
              "6          324        46.666667          0.466667           Neutral  \n",
              "7           31        87.096774          0.870968           Neutral  \n",
              "8           38        76.315789          0.763158           Neutral  \n",
              "9          153        44.078947          0.440789          Negative  \n",
              "10          39        82.051282          0.820513           Neutral  \n",
              "11           6       100.000000          1.000000           Neutral  \n",
              "12         406        41.379310          0.413793           Neutral  \n",
              "13         230        54.782609          0.547826          Negative  \n",
              "14          96        76.041667          0.760417          Positive  \n",
              "15         180        52.222222          0.522222           Neutral  \n",
              "16         361        52.908587          0.529086          Positive  \n",
              "17         129        50.387597          0.503876           Neutral  \n",
              "18         257        43.190661          0.431907          Positive  \n",
              "19         211        44.549763          0.445498          Negative  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subset con dato de Llama2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_promtp</th>\n",
              "      <th>answers</th>\n",
              "      <th>llm_model</th>\n",
              "      <th>lang</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>sentence_count</th>\n",
              "      <th>char_count</th>\n",
              "      <th>letter_count</th>\n",
              "      <th>lexicon_count</th>\n",
              "      <th>avg_sentence_length</th>\n",
              "      <th>avg_letter_per_word</th>\n",
              "      <th>qtty_stopwords</th>\n",
              "      <th>qtty_words</th>\n",
              "      <th>lexical_density</th>\n",
              "      <th>lexical_richness</th>\n",
              "      <th>analyze_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>\\n¡Buenos días! ¡Claro que sí! Estoy aquí para...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>2.60</td>\n",
              "      <td>3</td>\n",
              "      <td>177</td>\n",
              "      <td>169</td>\n",
              "      <td>39</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.33</td>\n",
              "      <td>21</td>\n",
              "      <td>39</td>\n",
              "      <td>82.051282</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>\\nLa capital de Francia es París.</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>25</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.17</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>\\n¡Por supuesto! Argentina es un país fascinan...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>29.10</td>\n",
              "      <td>25</td>\n",
              "      <td>1981</td>\n",
              "      <td>1918</td>\n",
              "      <td>406</td>\n",
              "      <td>16.2</td>\n",
              "      <td>4.72</td>\n",
              "      <td>168</td>\n",
              "      <td>406</td>\n",
              "      <td>41.379310</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>\\nInteligencia Artificial (IA) es el campo de ...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>18.36</td>\n",
              "      <td>10</td>\n",
              "      <td>1250</td>\n",
              "      <td>1224</td>\n",
              "      <td>227</td>\n",
              "      <td>22.7</td>\n",
              "      <td>5.39</td>\n",
              "      <td>99</td>\n",
              "      <td>230</td>\n",
              "      <td>54.782609</td>\n",
              "      <td>0.547826</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>\\nSure! Here is the translation of the text in...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>en</td>\n",
              "      <td>8.04</td>\n",
              "      <td>4</td>\n",
              "      <td>547</td>\n",
              "      <td>532</td>\n",
              "      <td>96</td>\n",
              "      <td>24.0</td>\n",
              "      <td>5.54</td>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "      <td>76.041667</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>\\nEl aire es libre, la brisa del mar\\nUna sens...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>11.43</td>\n",
              "      <td>1</td>\n",
              "      <td>778</td>\n",
              "      <td>764</td>\n",
              "      <td>180</td>\n",
              "      <td>180.0</td>\n",
              "      <td>4.24</td>\n",
              "      <td>99</td>\n",
              "      <td>180</td>\n",
              "      <td>52.222222</td>\n",
              "      <td>0.522222</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Título: \"The Audition\"\\n\\nAct 1:\\n\\nThe scene ...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>en</td>\n",
              "      <td>24.91</td>\n",
              "      <td>22</td>\n",
              "      <td>1696</td>\n",
              "      <td>1628</td>\n",
              "      <td>361</td>\n",
              "      <td>16.4</td>\n",
              "      <td>4.51</td>\n",
              "      <td>21</td>\n",
              "      <td>361</td>\n",
              "      <td>52.908587</td>\n",
              "      <td>0.529086</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>```\\nprint(\"Hola, mundo!\")\\n```\\nEste código u...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>10.30</td>\n",
              "      <td>8</td>\n",
              "      <td>701</td>\n",
              "      <td>645</td>\n",
              "      <td>125</td>\n",
              "      <td>15.6</td>\n",
              "      <td>5.16</td>\n",
              "      <td>53</td>\n",
              "      <td>129</td>\n",
              "      <td>50.387597</td>\n",
              "      <td>0.503876</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>\\n ¡Claro! Para analizar este conjunto de dato...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>20.18</td>\n",
              "      <td>13</td>\n",
              "      <td>1374</td>\n",
              "      <td>1232</td>\n",
              "      <td>246</td>\n",
              "      <td>18.9</td>\n",
              "      <td>5.01</td>\n",
              "      <td>102</td>\n",
              "      <td>257</td>\n",
              "      <td>43.190661</td>\n",
              "      <td>0.431907</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>\\nPuedes crear una función en PySpark utilizan...</td>\n",
              "      <td>llama2</td>\n",
              "      <td>es</td>\n",
              "      <td>18.32</td>\n",
              "      <td>14</td>\n",
              "      <td>1247</td>\n",
              "      <td>1117</td>\n",
              "      <td>202</td>\n",
              "      <td>14.4</td>\n",
              "      <td>5.53</td>\n",
              "      <td>82</td>\n",
              "      <td>211</td>\n",
              "      <td>44.549763</td>\n",
              "      <td>0.445498</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_promtp                                            answers llm_model  \\\n",
              "0          1  \\n¡Buenos días! ¡Claro que sí! Estoy aquí para...    llama2   \n",
              "1          2                  \\nLa capital de Francia es París.    llama2   \n",
              "2          3  \\n¡Por supuesto! Argentina es un país fascinan...    llama2   \n",
              "3          4  \\nInteligencia Artificial (IA) es el campo de ...    llama2   \n",
              "4          5  \\nSure! Here is the translation of the text in...    llama2   \n",
              "5          6  \\nEl aire es libre, la brisa del mar\\nUna sens...    llama2   \n",
              "6          7  Título: \"The Audition\"\\n\\nAct 1:\\n\\nThe scene ...    llama2   \n",
              "7          8  ```\\nprint(\"Hola, mundo!\")\\n```\\nEste código u...    llama2   \n",
              "8          9  \\n ¡Claro! Para analizar este conjunto de dato...    llama2   \n",
              "9         10  \\nPuedes crear una función en PySpark utilizan...    llama2   \n",
              "\n",
              "  lang  reading_time  sentence_count  char_count  letter_count  lexicon_count  \\\n",
              "0   es          2.60               3         177           169             39   \n",
              "1   es          0.38               1          26            25              6   \n",
              "2   es         29.10              25        1981          1918            406   \n",
              "3   es         18.36              10        1250          1224            227   \n",
              "4   en          8.04               4         547           532             96   \n",
              "5   es         11.43               1         778           764            180   \n",
              "6   en         24.91              22        1696          1628            361   \n",
              "7   es         10.30               8         701           645            125   \n",
              "8   es         20.18              13        1374          1232            246   \n",
              "9   es         18.32              14        1247          1117            202   \n",
              "\n",
              "   avg_sentence_length  avg_letter_per_word  qtty_stopwords  qtty_words  \\\n",
              "0                 13.0                 4.33              21          39   \n",
              "1                  6.0                 4.17               3           6   \n",
              "2                 16.2                 4.72             168         406   \n",
              "3                 22.7                 5.39              99         230   \n",
              "4                 24.0                 5.54               1          96   \n",
              "5                180.0                 4.24              99         180   \n",
              "6                 16.4                 4.51              21         361   \n",
              "7                 15.6                 5.16              53         129   \n",
              "8                 18.9                 5.01             102         257   \n",
              "9                 14.4                 5.53              82         211   \n",
              "\n",
              "   lexical_density  lexical_richness analyze_sentiment  \n",
              "0        82.051282          0.820513           Neutral  \n",
              "1       100.000000          1.000000           Neutral  \n",
              "2        41.379310          0.413793           Neutral  \n",
              "3        54.782609          0.547826          Negative  \n",
              "4        76.041667          0.760417          Positive  \n",
              "5        52.222222          0.522222           Neutral  \n",
              "6        52.908587          0.529086          Positive  \n",
              "7        50.387597          0.503876           Neutral  \n",
              "8        43.190661          0.431907          Positive  \n",
              "9        44.549763          0.445498          Negative  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_llm_llama = llm_df[llm_df['llm_model'] == 'llama2'].reset_index(drop=True)\n",
        "df_llm_llama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subset con dato de Gemma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_promtp</th>\n",
              "      <th>answers</th>\n",
              "      <th>llm_model</th>\n",
              "      <th>lang</th>\n",
              "      <th>reading_time</th>\n",
              "      <th>sentence_count</th>\n",
              "      <th>char_count</th>\n",
              "      <th>letter_count</th>\n",
              "      <th>lexicon_count</th>\n",
              "      <th>avg_sentence_length</th>\n",
              "      <th>avg_letter_per_word</th>\n",
              "      <th>qtty_stopwords</th>\n",
              "      <th>qtty_words</th>\n",
              "      <th>lexical_density</th>\n",
              "      <th>lexical_richness</th>\n",
              "      <th>analyze_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Claro, estoy aquí para ayudarte. ¿En qué puedo...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>0.75</td>\n",
              "      <td>2</td>\n",
              "      <td>51</td>\n",
              "      <td>47</td>\n",
              "      <td>10</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.70</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>La capital de Francia es **París**.</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.17</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>¡Claro que sí! Argentina es un país increíble ...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>22.59</td>\n",
              "      <td>19</td>\n",
              "      <td>1538</td>\n",
              "      <td>1390</td>\n",
              "      <td>282</td>\n",
              "      <td>14.8</td>\n",
              "      <td>4.93</td>\n",
              "      <td>120</td>\n",
              "      <td>297</td>\n",
              "      <td>49.831650</td>\n",
              "      <td>0.498316</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>## Inteligencia Artificial: La próxima generac...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>21.37</td>\n",
              "      <td>17</td>\n",
              "      <td>1455</td>\n",
              "      <td>1355</td>\n",
              "      <td>236</td>\n",
              "      <td>13.9</td>\n",
              "      <td>5.74</td>\n",
              "      <td>91</td>\n",
              "      <td>250</td>\n",
              "      <td>54.800000</td>\n",
              "      <td>0.548000</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>\"Martian Chronicles\" by Ray Bradbury is a coll...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>en</td>\n",
              "      <td>7.51</td>\n",
              "      <td>4</td>\n",
              "      <td>511</td>\n",
              "      <td>499</td>\n",
              "      <td>89</td>\n",
              "      <td>22.3</td>\n",
              "      <td>5.61</td>\n",
              "      <td>2</td>\n",
              "      <td>89</td>\n",
              "      <td>76.404494</td>\n",
              "      <td>0.764045</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>La sombra del poder se aleja,\\nel corazón del ...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>11.30</td>\n",
              "      <td>12</td>\n",
              "      <td>769</td>\n",
              "      <td>741</td>\n",
              "      <td>164</td>\n",
              "      <td>13.7</td>\n",
              "      <td>4.52</td>\n",
              "      <td>84</td>\n",
              "      <td>164</td>\n",
              "      <td>57.926829</td>\n",
              "      <td>0.579268</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>**Título:** El peor día de la vida de Juan\\n\\n...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>20.76</td>\n",
              "      <td>32</td>\n",
              "      <td>1413</td>\n",
              "      <td>1293</td>\n",
              "      <td>312</td>\n",
              "      <td>9.8</td>\n",
              "      <td>4.14</td>\n",
              "      <td>138</td>\n",
              "      <td>324</td>\n",
              "      <td>46.666667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>```python\\nprint(\"Hola, mundo!\")\\n```\\n\\nEste ...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>2.41</td>\n",
              "      <td>5</td>\n",
              "      <td>164</td>\n",
              "      <td>138</td>\n",
              "      <td>30</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>13</td>\n",
              "      <td>31</td>\n",
              "      <td>87.096774</td>\n",
              "      <td>0.870968</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>No se ha proporcionado ningún conjunto de dato...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>2.78</td>\n",
              "      <td>3</td>\n",
              "      <td>189</td>\n",
              "      <td>184</td>\n",
              "      <td>38</td>\n",
              "      <td>12.7</td>\n",
              "      <td>4.84</td>\n",
              "      <td>17</td>\n",
              "      <td>38</td>\n",
              "      <td>76.315789</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>```python\\nfrom pyspark.sql.functions import m...</td>\n",
              "      <td>gemma</td>\n",
              "      <td>es</td>\n",
              "      <td>11.78</td>\n",
              "      <td>11</td>\n",
              "      <td>802</td>\n",
              "      <td>702</td>\n",
              "      <td>135</td>\n",
              "      <td>12.3</td>\n",
              "      <td>5.20</td>\n",
              "      <td>44</td>\n",
              "      <td>153</td>\n",
              "      <td>44.078947</td>\n",
              "      <td>0.440789</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_promtp                                            answers llm_model  \\\n",
              "0          1  Claro, estoy aquí para ayudarte. ¿En qué puedo...     gemma   \n",
              "1          2                La capital de Francia es **París**.     gemma   \n",
              "2          3  ¡Claro que sí! Argentina es un país increíble ...     gemma   \n",
              "3          4  ## Inteligencia Artificial: La próxima generac...     gemma   \n",
              "4          5  \"Martian Chronicles\" by Ray Bradbury is a coll...     gemma   \n",
              "5          6  La sombra del poder se aleja,\\nel corazón del ...     gemma   \n",
              "6          7  **Título:** El peor día de la vida de Juan\\n\\n...     gemma   \n",
              "7          8  ```python\\nprint(\"Hola, mundo!\")\\n```\\n\\nEste ...     gemma   \n",
              "8          9  No se ha proporcionado ningún conjunto de dato...     gemma   \n",
              "9         10  ```python\\nfrom pyspark.sql.functions import m...     gemma   \n",
              "\n",
              "  lang  reading_time  sentence_count  char_count  letter_count  lexicon_count  \\\n",
              "0   es          0.75               2          51            47             10   \n",
              "1   es          0.44               1          30            25              6   \n",
              "2   es         22.59              19        1538          1390            282   \n",
              "3   es         21.37              17        1455          1355            236   \n",
              "4   en          7.51               4         511           499             89   \n",
              "5   es         11.30              12         769           741            164   \n",
              "6   es         20.76              32        1413          1293            312   \n",
              "7   es          2.41               5         164           138             30   \n",
              "8   es          2.78               3         189           184             38   \n",
              "9   es         11.78              11         802           702            135   \n",
              "\n",
              "   avg_sentence_length  avg_letter_per_word  qtty_stopwords  qtty_words  \\\n",
              "0                  5.0                 4.70               3          10   \n",
              "1                  6.0                 4.17               3           6   \n",
              "2                 14.8                 4.93             120         297   \n",
              "3                 13.9                 5.74              91         250   \n",
              "4                 22.3                 5.61               2          89   \n",
              "5                 13.7                 4.52              84         164   \n",
              "6                  9.8                 4.14             138         324   \n",
              "7                  6.0                 4.60              13          31   \n",
              "8                 12.7                 4.84              17          38   \n",
              "9                 12.3                 5.20              44         153   \n",
              "\n",
              "   lexical_density  lexical_richness analyze_sentiment  \n",
              "0        90.000000          0.900000           Neutral  \n",
              "1       100.000000          1.000000           Neutral  \n",
              "2        49.831650          0.498316           Neutral  \n",
              "3        54.800000          0.548000          Negative  \n",
              "4        76.404494          0.764045          Positive  \n",
              "5        57.926829          0.579268          Negative  \n",
              "6        46.666667          0.466667           Neutral  \n",
              "7        87.096774          0.870968           Neutral  \n",
              "8        76.315789          0.763158           Neutral  \n",
              "9        44.078947          0.440789          Negative  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_llm_gemma = llm_df[llm_df['llm_model'] == 'gemma'].reset_index(drop=True)\n",
        "df_llm_gemma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparacion de los valores de cada indicador obtenido para llama2 y gemma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'id_promtp',\n",
              " 1: 'answers',\n",
              " 2: 'llm_model',\n",
              " 3: 'lang',\n",
              " 4: 'reading_time',\n",
              " 5: 'sentence_count',\n",
              " 6: 'char_count',\n",
              " 7: 'letter_count',\n",
              " 8: 'lexicon_count',\n",
              " 9: 'avg_sentence_length',\n",
              " 10: 'avg_letter_per_word',\n",
              " 11: 'qtty_stopwords',\n",
              " 12: 'qtty_words',\n",
              " 13: 'lexical_density',\n",
              " 14: 'lexical_richness',\n",
              " 15: 'analyze_sentiment'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns = llm_df.columns.to_list()\n",
        "dict_cols = utils.list_to_dict(columns)\n",
        "dict_cols\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculo de cuantos registros son mejores, en un indicador determinado, entre un modelo y otro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>indicador</th>\n",
              "      <th>llama_better</th>\n",
              "      <th>gemma_better</th>\n",
              "      <th>equals</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reading_time</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sentence_count</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>char_count</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>letter_count</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lexicon_count</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>avg_sentence_length</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg_letter_per_word</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>qtty_stopwords</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>qtty_words</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>lexical_density</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lexical_richness</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>total_sum</td>\n",
              "      <td>31</td>\n",
              "      <td>69</td>\n",
              "      <td>10</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              indicador  llama_better  gemma_better  equals  total\n",
              "0          reading_time             2             8       0     10\n",
              "1        sentence_count             3             5       2     10\n",
              "2            char_count             2             8       0     10\n",
              "3          letter_count             1             8       1     10\n",
              "4         lexicon_count             1             8       1     10\n",
              "5   avg_sentence_length             0             9       1     10\n",
              "6   avg_letter_per_word             5             4       1     10\n",
              "7        qtty_stopwords             2             7       1     10\n",
              "8            qtty_words             1             8       1     10\n",
              "9       lexical_density             7             2       1     10\n",
              "10     lexical_richness             7             2       1     10\n",
              "11            total_sum            31            69      10    110"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final = pd.DataFrame()\n",
        "for col in dict_cols.values():\n",
        "    cols_not_indicators = ['id_promtp','answers','llm_model','lang','analyze_sentiment']\n",
        "    llama_count=0\n",
        "    gemma_count=0\n",
        "    iguales = 0\n",
        "\n",
        "    if col not in cols_not_indicators:\n",
        "        #print(f'{\"#\"*7}{col}{\"#\"*7} ')\n",
        "        for index in range(0, 10):\n",
        "            if df_llm_gemma[col][index] < df_llm_llama[col][index]:\n",
        "                #print('gema es mejor')\n",
        "                gemma_count += 1\n",
        "            elif df_llm_gemma[col][index] > df_llm_llama[col][index]:\n",
        "                #print('llama es mejor')\n",
        "                llama_count += 1\n",
        "            elif df_llm_gemma[col][index] == df_llm_llama[col][index]:\n",
        "                #print('son identicos')\n",
        "                iguales += 1\n",
        "            df_empty = pd.DataFrame({'indicador':[col], 'llama_better':[llama_count], 'gemma_better':[gemma_count], 'equals':[iguales]})\n",
        "#        print(col, llama_count, gemma_count, iguales)\n",
        "        df_final = pd.concat([df_final, df_empty])\n",
        " \n",
        "df_totales = pd.DataFrame({'indicador':'total_sum', 'llama_better':[df_final['llama_better'].sum()]\n",
        "                         , 'gemma_better':[df_final['gemma_better'].sum()], 'equals':df_final['equals'].sum()})        \n",
        "\n",
        "df_final = pd.concat([df_final, df_totales])      \n",
        "              \n",
        "df_final = df_final.reset_index(drop=True)\n",
        "numerical_columns = df_final.select_dtypes(include=[int, float]).columns\n",
        "df_final['total'] = df_final[numerical_columns].sum(axis=1)\n",
        "df_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>indicador</th>\n",
              "      <th>llama_better</th>\n",
              "      <th>gemma_better</th>\n",
              "      <th>equals</th>\n",
              "      <th>total</th>\n",
              "      <th>llama_better_percent</th>\n",
              "      <th>gemma_better_percent</th>\n",
              "      <th>equal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reading_time</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>20.00</td>\n",
              "      <td>80.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sentence_count</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>30.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>20.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>char_count</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>20.00</td>\n",
              "      <td>80.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>letter_count</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>10.00</td>\n",
              "      <td>80.00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lexicon_count</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>10.00</td>\n",
              "      <td>80.00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>avg_sentence_length</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>90.00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>avg_letter_per_word</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>50.00</td>\n",
              "      <td>40.00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>qtty_stopwords</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>20.00</td>\n",
              "      <td>70.00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>qtty_words</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>10.00</td>\n",
              "      <td>80.00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>lexical_density</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>70.00</td>\n",
              "      <td>20.00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lexical_richness</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>70.00</td>\n",
              "      <td>20.00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>total_sum</td>\n",
              "      <td>31</td>\n",
              "      <td>69</td>\n",
              "      <td>10</td>\n",
              "      <td>110</td>\n",
              "      <td>28.18</td>\n",
              "      <td>62.73</td>\n",
              "      <td>9.09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              indicador  llama_better  gemma_better  equals  total  \\\n",
              "0          reading_time             2             8       0     10   \n",
              "1        sentence_count             3             5       2     10   \n",
              "2            char_count             2             8       0     10   \n",
              "3          letter_count             1             8       1     10   \n",
              "4         lexicon_count             1             8       1     10   \n",
              "5   avg_sentence_length             0             9       1     10   \n",
              "6   avg_letter_per_word             5             4       1     10   \n",
              "7        qtty_stopwords             2             7       1     10   \n",
              "8            qtty_words             1             8       1     10   \n",
              "9       lexical_density             7             2       1     10   \n",
              "10     lexical_richness             7             2       1     10   \n",
              "11            total_sum            31            69      10    110   \n",
              "\n",
              "    llama_better_percent  gemma_better_percent  equal  \n",
              "0                  20.00                 80.00   0.00  \n",
              "1                  30.00                 50.00  20.00  \n",
              "2                  20.00                 80.00   0.00  \n",
              "3                  10.00                 80.00  10.00  \n",
              "4                  10.00                 80.00  10.00  \n",
              "5                   0.00                 90.00  10.00  \n",
              "6                  50.00                 40.00  10.00  \n",
              "7                  20.00                 70.00  10.00  \n",
              "8                  10.00                 80.00  10.00  \n",
              "9                  70.00                 20.00  10.00  \n",
              "10                 70.00                 20.00  10.00  \n",
              "11                 28.18                 62.73   9.09  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# muestro los valores obtenidos anteriormente de forma porcentual\n",
        "df_final['llama_better_percent'] = round((df_final['llama_better']/df_final['total'])*100,2)\n",
        "df_final['gemma_better_percent'] = round((df_final['gemma_better']/df_final['total'])*100,2)\n",
        "df_final['equal'] = round((df_final['equals']/df_final['total'])*100,2)\n",
        "df_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparacion de los promedios de cada colummnas numerica para cada indicador obtenidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Columnas numericas de los dataframes, al ser ambos un subset del dataframe principal\n",
        "# se posee certeza que las columnas son identicas\n",
        "numeric_cols =['reading_time','sentence_count','char_count','letter_count','lexicon_count','avg_sentence_length'\n",
        "              ,'avg_letter_per_word','qtty_stopwords','qtty_words','lexical_density','lexical_richness']   \n",
        "\n",
        "#Promedio los valores de cada variables/columnas numericas de gemma y las guardo en un diccionario\n",
        "dict_prom_gemma = df_llm_gemma[numeric_cols].mean().to_dict()\n",
        "#Promedio los valores de cada variables/columnas numericas de llama2 y las guardo en un diccionario\n",
        "dict_prom_llama2 = df_llm_llama[numeric_cols].mean().to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparacion del promedio de reading_time \n",
            "El valor promedio de los valores obtenidos para reading_time son mejores en gemma:7b por sobre llama2.\n",
            "gemma: 10.169 - llama2: 14.362\n",
            "\n",
            "Comparacion del promedio de sentence_count \n",
            "El valor promedio de los valores obtenidos para sentence_count son mejores en llama2 por sobre gemma.\n",
            "gemma: 10.6 - llama2: 10.1\n",
            "\n",
            "Comparacion del promedio de char_count \n",
            "El valor promedio de los valores obtenidos para char_count son mejores en gemma:7b por sobre llama2.\n",
            "gemma: 692.2 - llama2: 977.7\n",
            "\n",
            "Comparacion del promedio de letter_count \n",
            "El valor promedio de los valores obtenidos para letter_count son mejores en gemma:7b por sobre llama2.\n",
            "gemma: 637.4 - llama2: 925.4\n",
            "\n",
            "Comparacion del promedio de lexicon_count \n",
            "El valor promedio de los valores obtenidos para lexicon_count son mejores en gemma:7b por sobre llama2.\n",
            "gemma: 130.2 - llama2: 188.8\n",
            "\n",
            "Comparacion del promedio de avg_sentence_length \n",
            "El valor promedio de los valores obtenidos para avg_sentence_length son mejores en gemma:7b por sobre llama2.\n",
            "gemma: 11.65 - llama2: 32.71999999999999\n",
            "\n",
            "Comparacion del promedio de avg_letter_per_word \n",
            "El valor promedio de los valores obtenidos para avg_letter_per_word son mejores en gemma:7b por sobre llama2.\n",
            "gemma: 4.845000000000001 - llama2: 4.86\n",
            "\n",
            "Comparacion del promedio de qtty_stopwords \n",
            "El valor promedio de los valores obtenidos para qtty_stopwords son mejores en gemma:7b por sobre llama2.\n",
            "gemma: 51.5 - llama2: 64.9\n",
            "\n",
            "Comparacion del promedio de qtty_words \n",
            "El valor promedio de los valores obtenidos para qtty_words son mejores en gemma:7b por sobre llama2.\n",
            "gemma: 136.2 - llama2: 191.5\n",
            "\n",
            "Comparacion del promedio de lexical_density \n",
            "El valor promedio de los valores obtenidos para lexical_density son mejores en llama2 por sobre gemma.\n",
            "gemma: 68.31211511842852 - llama2: 59.75136986492678\n",
            "\n",
            "Comparacion del promedio de lexical_richness \n",
            "El valor promedio de los valores obtenidos para lexical_richness son mejores en llama2 por sobre gemma.\n",
            "gemma: 0.6831211511842854 - llama2: 0.5975136986492677\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# como ambos dataframes son identicos tomo uno para obtener las key y comparar los promedios de cada variable\n",
        "keys = dict_prom_gemma.keys()\n",
        "for key in keys:\n",
        "    print(f'Comparacion del promedio de {key} ')\n",
        "    if dict_prom_gemma[key] == dict_prom_llama2[key]:\n",
        "        print( f'El valor promedio de los valores obtenidos para {key} son identicos. No se puede determinar cual es el mejor en este aspecto\\n'\n",
        "               f'gemma: {dict_prom_gemma[key]} - llama2: {dict_prom_llama2[key]}\\n'\n",
        "              )\n",
        "    elif dict_prom_gemma[key] < dict_prom_llama2[key]:\n",
        "        print( f'El valor promedio de los valores obtenidos para {key} son mejores en gemma:7b por sobre llama2.\\n'\n",
        "               f'gemma: {dict_prom_gemma[key]} - llama2: {dict_prom_llama2[key]}\\n')\n",
        "    elif dict_prom_gemma[key] > dict_prom_llama2[key]:\n",
        "        print( f'El valor promedio de los valores obtenidos para {key} son mejores en llama2 por sobre gemma.\\n'\n",
        "               f'gemma: {dict_prom_gemma[key]} - llama2: {dict_prom_llama2[key]}\\n')\n",
        "    else:\n",
        "        print( f'Para el indicador promedio {key} no se puede determinar benchmark\\n')\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
