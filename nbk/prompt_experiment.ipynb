{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Experimento prompts**\n",
    "Generar Datos de respuesta de los PROMPTS y almacenarlos SQLITE para su posterior analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defino los imports a utilizar a lo largo del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from ollama import Client\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defino las funciones a utilizar en la celda principal del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Funciones\n",
    "def get_list_tbl(tbl_name, conn):\n",
    "    \"\"\"\n",
    "    The function `get_list_tbl` retrieves the names of tables in a SQLite database that match a\n",
    "    specified name.\n",
    "    \n",
    "    :param tbl_name: The `tbl_name` parameter in the `get_list_tbl` function is used to specify the name\n",
    "    of the table for which you want to retrieve information from the SQLite database. The function will\n",
    "    query the database to fetch the names of tables that match the provided `tbl_name`\n",
    "    :return: The function `get_list_tbl(tbl_name)` returns a DataFrame containing the names of tables in\n",
    "    a SQLite database that match the input table name `tbl_name`.\n",
    "    \"\"\"\n",
    "    df_tbls_names = pd.read_sql_query(f\"SELECT name FROM sqlite_master where name='{tbl_name}'\", conn)\n",
    "    return df_tbls_names\n",
    "\n",
    "# get_response_from_llm('https://9f0c-34-126-167-50.ngrok-free.app', 'llama2/llama3/gemma:7b', text_prompt)\n",
    "def get_response_from_llm(client, llm_model, text_prompt): #url:\n",
    "    \"\"\"\n",
    "    The function `get_response_from_llm` takes in a URL host, a GPT-3 model, and a text prompt, then\n",
    "    uses a client to chat with the specified model and returns the response content.\n",
    "    \n",
    "    :param url_host: The `url_host` parameter refers to the host URL where the language model API is\n",
    "    hosted. This is the endpoint that the client will connect to in order to interact with the language\n",
    "    model\n",
    "    :param llm_model: The `llm_model` parameter refers to the specific language model that will be used\n",
    "    for generating responses. It could be a model like `llama2`, `llama3`, or `gemma:7b`. This parameter\n",
    "    determines the characteristics and capabilities of the language model being utilized for the\n",
    "    :param text_prompt: The `text_prompt` parameter is the text input or prompt that you want to send to\n",
    "    the language model for generating a response. It is the message that you want the model to respond\n",
    "    to\n",
    "    :return: The function `get_response_from_llm` is returning the content of the response message from\n",
    "    the language model (LLM) after sending a text prompt to it.\n",
    "    \"\"\"\n",
    "\n",
    "    #client = Client(host=url_host) # este hay que cambiarlo por el que da Colab\n",
    "    response = client.chat(model=llm_model # llama2/llama3/gemma:7b\n",
    "                           , messages=[\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': text_prompt,\n",
    "      },\n",
    "    ])\n",
    "\n",
    "    return response['message']['content']\n",
    "\n",
    "\n",
    "def get_prompts_from_tbl(df,conn):\n",
    "    \"\"\"\n",
    "    The function `get_prompts_from_tbl` iterates through a DataFrame, prints a header for each row, and\n",
    "    then retrieves the first 3 rows from a table in a database connection.\n",
    "    \n",
    "    :param df: The `df` parameter is a DataFrame containing information about tables in a database. It\n",
    "    is used to iterate over each row to retrieve prompts from each table\n",
    "    :param conn: The `conn` parameter in the function `get_prompts_from_tbl` is likely a database\n",
    "    connection object that allows you to interact with a database. It is used to execute SQL queries\n",
    "    against the database specified in the connection\n",
    "    :return: The function `get_prompts_from_tbl` is returning the DataFrame `df_prompts` which contains\n",
    "    the result of the SQL query selecting all columns from the table specified in the `name` column of\n",
    "    the input DataFrame `df`, limited to 3 rows.\n",
    "    \"\"\"\n",
    "\n",
    "    for _, row in df.iterrows(): # no uso info de index\n",
    "      print(f\"\\n#### {row['name']} ####\\n\")\n",
    "      df_prompts = pd.read_sql_query(f\"SELECT * FROM {row['name']} limit 11\", conn)\n",
    "    return df_prompts\n",
    "\n",
    "\n",
    "def get_prompts_answer(df_prompts, ollama_client, model_llm):\n",
    "    \"\"\"\n",
    "    The function `get_prompts_answer` iterates through prompts in a DataFrame, generates responses using\n",
    "    a language model, and returns a DataFrame with prompt IDs and corresponding answers.\n",
    "    \n",
    "    :param df_prompts: The `df_prompts` parameter is likely a DataFrame containing prompts with their\n",
    "    corresponding IDs. The function `get_prompts_answer` iterates over each row in this DataFrame,\n",
    "    retrieves a response using the OpenAI Language Model (OLLAMA), and stores the prompt ID and response\n",
    "    in a dictionary\n",
    "    :param ollama_client: The `ollama_client` parameter is likely an object or client used to interact\n",
    "    with the OpenAI Language Model API. It is used in the `get_response_from_llm` function to make\n",
    "    requests to the language model and retrieve responses based on the provided prompts\n",
    "    :return: The function `get_prompts_answer` returns a pandas DataFrame containing two columns:\n",
    "    'id_prompts' and 'answers'. The 'id_prompts' column contains a list of prompt IDs from the input\n",
    "    DataFrame `df_prompts`, and the 'answers' column contains a list of responses generated by the\n",
    "    `get_response_from_llm` function using the prompts provided in the 'prompt' column of\n",
    "    \"\"\"\n",
    "\n",
    "    dict_prompt_answer = {}\n",
    "    list_id_prompts = []\n",
    "    list_prompt_answers = []      \n",
    "      \n",
    "    for index, row in df_prompts.iterrows():\n",
    "      print(row['id_promtp'], row['prompt'])\n",
    "      #####\n",
    "      llm_reponse = get_response_from_llm(client = ollama_client\n",
    "                                          , llm_model = model_llm #'llama2' # 'llama2/llama3/gemma:7b'\n",
    "                                          , text_prompt = row['prompt']\n",
    "                                          )\n",
    "      #####\n",
    "       \n",
    "      list_id_prompts.append(row['id_promtp'])\n",
    "      list_prompt_answers.append(llm_reponse)\n",
    "    \n",
    "    dict_prompt_answer['id_prompts'] = list_id_prompts\n",
    "    dict_prompt_answer['answers'] = list_prompt_answers\n",
    "    return pd.DataFrame(dict_prompt_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Main**\n",
    "Celda principal del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### set_1 ####\n",
      "\n",
      "1 Buenos días, ¿me podrias ayudar con algo hoy?\n",
      "2 ¿Cuál es la capital de Francia?\n",
      "3 Estoy planeando un viaje a Argentina. ¿Podrías recomendarme algunos lugares para visitar?\n",
      "4 Por favor, podrias escibir un  artículo sobre la inteligencia artificial de no mas de 300 palabras\n",
      "5 Traduce este texto \"\"Crónicas Marcianas\" de Ray Bradbury es una colección de relatos que exploran la colonización humana en Marte. Con una prosa poética y visionaria, Bradbury teje historias emotivas sobre la soledad, la nostalgia y la naturaleza humana a través de encuentros imaginativos entre colonizadores y marcianos. Cada relato revela la fragilidad de la existencia y la búsqueda de significado en un mundo alienígena, mientras refleja paralelos con la condición humana en la Tierra. Esta obra maestra de la ciencia ficción cautiva con su estilo evocador y su capacidad para trascender lo tecnológico, adentrándose en lo más profundo del alma humana.\" del español al inglés.\n",
      "6 Escribe un poema sobre el libertad\n",
      "7 Escribe un guión para un cortometraje de comedia.\n",
      "8 Escribe un código en Python que imprima \"Hola, mundo!\" en la consola.\n",
      "9 Utiliza Pandas para analizar este conjunto de datos y generar un gráfico de barras.\n",
      "10 Crea una función en PySpark que calcule la media de un campo en un conjunto de datos.\n",
      "tiempo de ejecucion:0:01:54.866294\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    \"\"\"\n",
    "    Main function that runs the script.\n",
    "    It connects to a SQLite database, retrieves a table and a model name,\n",
    "    creates a client for the OpenAI Language Model API, retrieves prompts from the\n",
    "    table and their corresponding answers, and stores the results in a new table in the database.\n",
    "    \"\"\"\n",
    "\n",
    "    begin_time = datetime.datetime.now()\n",
    "\n",
    "    # Defino la ubicacion de la bbdd Sqlite a utilizar\n",
    "    con = sqlite3.connect('./db/prompt_sqlite.db')\n",
    "    \n",
    "    # Defino el nombre de la tabla que se utilizara\n",
    "    tbl = 'set_1'\n",
    "    # Defino el nombre del modelo a utilizar 'llama2/gemma:7b'\n",
    "    model_llm = 'gemma:7b' \n",
    "\n",
    "    # Obtengo los nombres de las tablas\n",
    "    df_tbls = get_list_tbl(tbl, con)\n",
    "    # Obtengo los prompts a enviar al modelo\n",
    "    df_prompts = get_prompts_from_tbl(df_tbls, con)\n",
    "    \n",
    "    # Configuro el Cliente con la URL del servidor donde se encuentra el modelo\n",
    "    # Se debe colocar la URL devuelta por NGROK en el entorno creado en Google Colab\n",
    "    url_host = 'URL host retrive by ngrok by google Colab' \n",
    "    ollama_client = Client(host=url_host)\n",
    "    \n",
    "    # Obtengo un dataframe con las respuestas que otorga el modelo \n",
    "    df_prompts_answer = get_prompts_answer(df_prompts, ollama_client, model_llm)\n",
    "\n",
    "    # Creo la tabla donde se guardaran los resultados(respuestas) a los prompts\n",
    "    print(f'\\nCreando tabla {tbl}_{model_llm}')\n",
    "    df_prompts_answer.to_sql(f'{tbl}_{model_llm}', con, if_exists='replace', index=False)\n",
    "    print(f'Tabla {tbl}_{model_llm} creada correctamente')\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    print('tiempo de ejecucion:' + str(end_time-begin_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Verificacion ####\n",
    "\n",
    "Verifico los dataframes con las respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>set_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name\n",
       "0  set_1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe con los nombres de las tablas de la BBDD\n",
    "df_tbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_promtp</th>\n",
       "      <th>complejidad</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Baja</td>\n",
       "      <td>Buenos días, ¿me podrias ayudar con algo hoy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Baja</td>\n",
       "      <td>¿Cuál es la capital de Francia?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Media</td>\n",
       "      <td>Estoy planeando un viaje a Argentina. ¿Podrías...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Media</td>\n",
       "      <td>Por favor, podrias escibir un  artículo sobre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Media</td>\n",
       "      <td>Traduce este texto \"\"Crónicas Marcianas\" de Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Media</td>\n",
       "      <td>Escribe un poema sobre el libertad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Media</td>\n",
       "      <td>Escribe un guión para un cortometraje de comedia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Escribe un código en Python que imprima \"Hola,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Utiliza Pandas para analizar este conjunto de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Crea una función en PySpark que calcule la med...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_promtp complejidad                                             prompt\n",
       "0          1        Baja      Buenos días, ¿me podrias ayudar con algo hoy?\n",
       "1          2        Baja                    ¿Cuál es la capital de Francia?\n",
       "2          3       Media  Estoy planeando un viaje a Argentina. ¿Podrías...\n",
       "3          4       Media  Por favor, podrias escibir un  artículo sobre ...\n",
       "4          5       Media  Traduce este texto \"\"Crónicas Marcianas\" de Ra...\n",
       "5          6       Media                 Escribe un poema sobre el libertad\n",
       "6          7       Media  Escribe un guión para un cortometraje de comedia.\n",
       "7          8        Alta  Escribe un código en Python que imprima \"Hola,...\n",
       "8          9        Alta  Utiliza Pandas para analizar este conjunto de ...\n",
       "9         10        Alta  Crea una función en PySpark que calcule la med..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe con los prompts de las tablas obtenida en el dataframe df_tbls\n",
    "df_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_prompts</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Claro, estaré encantado de ayudarte con algo h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>La capital de Francia es **París**.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>¡Claro que sí! Argentina es un país increíble ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>## Inteligencia Artificial: La próxima revoluc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Crónicas Marcianas\" by Ray Bradbury is a coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Libertad, un viento que sucia las alas,\\nque a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>## El Desastres de la Pizza\\n\\n**Personajes:**...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>```python\\nprint(\"Hola, mundo!\")\\n```\\n\\nEste ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>```python\\nimport pandas as pd\\nimport matplot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>```python\\nimport pyspark.sql.functions as F\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_prompts                                            answers\n",
       "0           1  Claro, estaré encantado de ayudarte con algo h...\n",
       "1           2                La capital de Francia es **París**.\n",
       "2           3  ¡Claro que sí! Argentina es un país increíble ...\n",
       "3           4  ## Inteligencia Artificial: La próxima revoluc...\n",
       "4           5  \"Crónicas Marcianas\" by Ray Bradbury is a coll...\n",
       "5           6  Libertad, un viento que sucia las alas,\\nque a...\n",
       "6           7  ## El Desastres de la Pizza\\n\\n**Personajes:**...\n",
       "7           8  ```python\\nprint(\"Hola, mundo!\")\\n```\\n\\nEste ...\n",
       "8           9  ```python\\nimport pandas as pd\\nimport matplot...\n",
       "9          10  ```python\\nimport pyspark.sql.functions as F\\n..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe con las respuestas a los prompts que se tienen en el dataframe df_prompts\n",
    "df_prompts_answer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
