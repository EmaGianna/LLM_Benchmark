{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Experimento prompts**\n",
    "Generar Datos de respuesta de los PROMPTS y almacenarlos SQLITE para su posterior analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from ollama import Client\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Funciones\n",
    "def get_list_tbl(tbl_name):\n",
    "    \"\"\"\n",
    "    The function `get_list_tbl` retrieves the names of tables in a SQLite database that match a\n",
    "    specified name.\n",
    "    \n",
    "    :param tbl_name: The `tbl_name` parameter in the `get_list_tbl` function is used to specify the name\n",
    "    of the table for which you want to retrieve information from the SQLite database. The function will\n",
    "    query the database to fetch the names of tables that match the provided `tbl_name`\n",
    "    :return: The function `get_list_tbl(tbl_name)` returns a DataFrame containing the names of tables in\n",
    "    a SQLite database that match the input table name `tbl_name`.\n",
    "    \"\"\"\n",
    "    df_tbls_names = pd.read_sql_query(f\"SELECT name FROM sqlite_master where name='{tbl_name}'\")\n",
    "    return df_tbls_names\n",
    "\n",
    "# get_response_from_llm('https://9f0c-34-126-167-50.ngrok-free.app', 'llama2/llama3/gemma:7b', text_prompt)\n",
    "def get_response_from_llm(client, llm_model, text_prompt): #url:\n",
    "    \"\"\"\n",
    "    The function `get_response_from_llm` takes in a URL host, a GPT-3 model, and a text prompt, then\n",
    "    uses a client to chat with the specified model and returns the response content.\n",
    "    \n",
    "    :param url_host: The `url_host` parameter refers to the host URL where the language model API is\n",
    "    hosted. This is the endpoint that the client will connect to in order to interact with the language\n",
    "    model\n",
    "    :param llm_model: The `llm_model` parameter refers to the specific language model that will be used\n",
    "    for generating responses. It could be a model like `llama2`, `llama3`, or `gemma:7b`. This parameter\n",
    "    determines the characteristics and capabilities of the language model being utilized for the\n",
    "    :param text_prompt: The `text_prompt` parameter is the text input or prompt that you want to send to\n",
    "    the language model for generating a response. It is the message that you want the model to respond\n",
    "    to\n",
    "    :return: The function `get_response_from_llm` is returning the content of the response message from\n",
    "    the language model (LLM) after sending a text prompt to it.\n",
    "    \"\"\"\n",
    "\n",
    "    #client = Client(host=url_host) # este hay que cambiarlo por el que da Colab\n",
    "    response = client.chat(model=llm_model # llama2/llama3/gemma:7b\n",
    "                           , messages=[\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': text_prompt,\n",
    "      },\n",
    "    ])\n",
    "\n",
    "    return response['message']['content']\n",
    "\n",
    "\n",
    "def get_prompts_from_tbl(df,conn):\n",
    "    \"\"\"\n",
    "    The function `get_prompts_from_tbl` iterates through a DataFrame, prints a header for each row, and\n",
    "    then retrieves the first 3 rows from a table in a database connection.\n",
    "    \n",
    "    :param df: The `df` parameter is a DataFrame containing information about tables in a database. It\n",
    "    is used to iterate over each row to retrieve prompts from each table\n",
    "    :param conn: The `conn` parameter in the function `get_prompts_from_tbl` is likely a database\n",
    "    connection object that allows you to interact with a database. It is used to execute SQL queries\n",
    "    against the database specified in the connection\n",
    "    :return: The function `get_prompts_from_tbl` is returning the DataFrame `df_prompts` which contains\n",
    "    the result of the SQL query selecting all columns from the table specified in the `name` column of\n",
    "    the input DataFrame `df`, limited to 3 rows.\n",
    "    \"\"\"\n",
    "\n",
    "    for _, row in df.iterrows(): # no uso info de index\n",
    "      print(f\"\\n#### {row['name']} ####\\n\")\n",
    "      df_prompts = pd.read_sql_query(f\"SELECT * FROM {row['name']} limit 11\", conn)\n",
    "    return df_prompts\n",
    "\n",
    "\n",
    "def get_prompts_answer(df_prompts, ollama_client, model_llm):\n",
    "    \"\"\"\n",
    "    The function `get_prompts_answer` iterates through prompts in a DataFrame, generates responses using\n",
    "    a language model, and returns a DataFrame with prompt IDs and corresponding answers.\n",
    "    \n",
    "    :param df_prompts: The `df_prompts` parameter is likely a DataFrame containing prompts with their\n",
    "    corresponding IDs. The function `get_prompts_answer` iterates over each row in this DataFrame,\n",
    "    retrieves a response using the OpenAI Language Model (OLLAMA), and stores the prompt ID and response\n",
    "    in a dictionary\n",
    "    :param ollama_client: The `ollama_client` parameter is likely an object or client used to interact\n",
    "    with the OpenAI Language Model API. It is used in the `get_response_from_llm` function to make\n",
    "    requests to the language model and retrieve responses based on the provided prompts\n",
    "    :return: The function `get_prompts_answer` returns a pandas DataFrame containing two columns:\n",
    "    'id_prompts' and 'answers'. The 'id_prompts' column contains a list of prompt IDs from the input\n",
    "    DataFrame `df_prompts`, and the 'answers' column contains a list of responses generated by the\n",
    "    `get_response_from_llm` function using the prompts provided in the 'prompt' column of\n",
    "    \"\"\"\n",
    "\n",
    "    dict_prompt_answer = {}\n",
    "    list_id_prompts = []\n",
    "    list_prompt_answers = []      \n",
    "      \n",
    "    for index, row in df_prompts.iterrows():\n",
    "      print(row['id_promtp'], row['prompt'])\n",
    "      #####\n",
    "      llm_reponse = get_response_from_llm(client = ollama_client\n",
    "                                          , llm_model = model_llm #'llama2' # 'llama2/llama3/gemma:7b'\n",
    "                                          , text_prompt = row['prompt']\n",
    "                                          )\n",
    "      #####\n",
    "       \n",
    "      list_id_prompts.append(row['id_promtp'])\n",
    "      list_prompt_answers.append(llm_reponse)\n",
    "    \n",
    "    dict_prompt_answer['id_prompts'] = list_id_prompts\n",
    "    dict_prompt_answer['answers'] = list_prompt_answers\n",
    "    return pd.DataFrame(dict_prompt_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    \"\"\"\n",
    "    Main function that runs the script.\n",
    "    It connects to a SQLite database, retrieves a table and a model name,\n",
    "    creates a client for the OpenAI Language Model API, retrieves prompts from the\n",
    "    table and their corresponding answers, and stores the results in a new table in the database.\n",
    "    \"\"\"\n",
    "\n",
    "    begin_time = datetime.datetime.now()\n",
    "\n",
    "    # Defino la ubicacion de la bbdd Sqlite a utilizar\n",
    "    con = sqlite3.connect('/mnt/e/Facultad/Licenciatura en Ciencia de Datos-UGR/Cursada/Tercer Cuatrimestre/'\n",
    "                      'Seminario_Trabajo_Final/Test_IA_models/Prompts/db/prompt_sqlite.db')\n",
    "    # Defino el nombre de la tabla que se utilizara\n",
    "    tbl = 'set_Extra_Muy_Alto'\n",
    "    # Defino el nombre del modelo a utilizar 'llama2/gemma:7b'\n",
    "    model_llm = 'gemma:7b' \n",
    "\n",
    "    # Obtengo los nombres de las tablas\n",
    "    df_tbls = get_list_tbl(tbl)\n",
    "    # Obtengo los prompts a enviar al modelo\n",
    "    df_prompts = get_prompts_from_tbl(df_tbls, con)\n",
    "    \n",
    "    # Configuro el Cliente con la URL del servidor donde se encuentra el modelo\n",
    "    url_host = 'https://86f6-34-16-199-170.ngrok-free.app'\n",
    "    ollama_client = Client(host=url_host)\n",
    "    \n",
    "    # Obtengo un dataframe con las respuestas que otorga el modelo \n",
    "    df_prompts_answer = get_prompts_answer(df_prompts, ollama_client, model_llm)\n",
    "\n",
    "    # Creo la tabla donde se guardaran los resultados(respuestas) a los prompts\n",
    "    print(f'\\nCreando tabla {tbl}_{model_llm}')\n",
    "    df_prompts_answer.to_sql(f'{tbl}_{model_llm}', con, if_exists='replace', index=False)\n",
    "    print(f'Tabla {tbl}_{model_llm} creada correctamente')\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    print('tiempo de ejecucion:' + str(end_time-begin_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Verificacion ####\n",
    "\n",
    "Verifico el Dataframe con las respuestas dadas por el modelo, los cuales se almacenaron en la tabla "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_prompts</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n¡Buenos días! ¡Claro que sí! Estoy aquí para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\nLa capital de Francia es París.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n¡Por supuesto! Argentina es un país fascinan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\\nInteligencia Artificial (IA) es el campo de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\\nSure! Here is the translation of the text in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\\nEl aire es libre, la brisa del mar\\nUna sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Título: \"The Audition\"\\n\\nAct 1:\\n\\nThe scene ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>```\\nprint(\"Hola, mundo!\")\\n```\\nEste código u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\\n ¡Claro! Para analizar este conjunto de dato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\\nPuedes crear una función en PySpark utilizan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_prompts                                            answers\n",
       "0           1  \\n¡Buenos días! ¡Claro que sí! Estoy aquí para...\n",
       "1           2                  \\nLa capital de Francia es París.\n",
       "2           3  \\n¡Por supuesto! Argentina es un país fascinan...\n",
       "3           4  \\nInteligencia Artificial (IA) es el campo de ...\n",
       "4           5  \\nSure! Here is the translation of the text in...\n",
       "5           6  \\nEl aire es libre, la brisa del mar\\nUna sens...\n",
       "6           7  Título: \"The Audition\"\\n\\nAct 1:\\n\\nThe scene ...\n",
       "7           8  ```\\nprint(\"Hola, mundo!\")\\n```\\nEste código u...\n",
       "8           9  \\n ¡Claro! Para analizar este conjunto de dato...\n",
       "9          10  \\nPuedes crear una función en PySpark utilizan..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompts_answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
